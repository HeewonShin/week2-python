import openai
import secrets

openai.api_key = secrets.API_KEY





while True:
    # 질문하기
    question = input('chatGPT에게 질문할 내용을 입력하세요(q:종료) : ')
    if question == 'q':
        print('종료')
        break
        
    
    '''응답 빨리 받기  # 참고 : examples/How_to_stream_completions.ipynb
    To get responses sooner, you can 'stream' the completion as it's being generated. This allows you to start printing or processing the beginning of the completion before the full completion is finished.

    To stream completions, set stream=True when calling the chat completions or completions endpoints. This will return an object that streams back the response as data-only server-sent events. Extract chunks from the delta field rather than the message field.'''

    
        # # chatGPT API 호출
    response = openai.ChatCompletion.create(
        model = 'gpt-3.5-turbo',
        messages = [  # 메시지 설정
        {'role': 'user', 'content': question}
    ],
        temperature = 0,
        stream = True
    )
    
        # create variables to collect the stream of chunks
    collected_chunks = []
    collected_messages = []
    # iterate through the stream of events
    for chunk in response:
        
        collected_chunks.append(chunk)  # save the event response
        chunk_message = chunk['choices'][0]['delta']  # extract the message
        collected_messages.append(chunk_message)  # save the message
    

    full_reply_content = ''.join([m.get('content', '') for m in collected_messages])
    print(f"답변 : {full_reply_content}")


# stream 사용하지 않은 기본 ver.
    # 참고 링크 : examples/How_to_format_inputs_to_ChatGPT_models.ipynb
    # # chatGPT API 호출
    # response = openai.ChatCompletion.create(
    #     model = 'gpt-3.5-turbo',
    #     messages = [  # 메시지 설정
    #     {'role': 'user', 'content': question}
    # ]
    # )
    
    # # 응답 출력
    # print(response["choices"][0]["message"]["content"])   
    
    # response 구조    
    '''<OpenAIObject chat.completion id=chatcmpl-7UkgnSDzlevZxiy0YjZcLYdUMz5yZ at 0x118e394f0> JSON: {
    "id": "chatcmpl-7UkgnSDzlevZxiy0YjZcLYdUMz5yZ",
    "object": "chat.completion",
    "created": 1687563669,
    "model": "gpt-3.5-turbo-0301",
    "choices": [
        {
        "index": 0,
        "message": {
            "role": "assistant",
            "content": "Orange who?"
        },
        "finish_reason": "stop"
        }
    ],
    "usage": {
        "prompt_tokens": 39,
        "completion_tokens": 3,
        "total_tokens": 42
    }
    }
    '''    
        
    '''choices: a list of completion objects (only one, unless you set n greater than 1)
            message: the message object generated by the model, with role and content
            finish_reason: the reason the model stopped generating text (either stop, or length if max_tokens limit was reached)
            index: the index of the completion in the list of choices'''



